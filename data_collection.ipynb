{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52420853",
   "metadata": {},
   "source": [
    "# Functions that edit On3 Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f72462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_ratings_and_school(url):\n",
    "    '''\n",
    "    Gets player ratings + school name\n",
    "    Input: url\n",
    "    Output: dataframe with all info from that on3 webpage\n",
    "    '''\n",
    "    \n",
    "    response = requests.get(url) \n",
    "        #requests.get returns a requests.response object. \n",
    "        #This sends an HTTP get request. The server responds with the desired info\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        #reuturns beautiful soup object to scrape data\n",
    "        #response.text: tells computer to scrape the HTML content\n",
    "        #html.parser: parser library that BeautifulSoup uses to parse HTML\n",
    "    \n",
    "    players = soup.find_all('li', class_ = \"IndustryComparisonList_industryComparisonItemContainer__QNFjk\")\n",
    "        #finds all div elements with the CSS class \"player card\"\n",
    "        #find_all method returns a ResultSet object (iterable like a list)\n",
    "        #each element in the ResultSet object is a Tag object to further search\n",
    "\n",
    "    data = []\n",
    "    curr_player = 0\n",
    "    \n",
    "    for player in players:\n",
    "        data.append(create_player(player, curr_player))\n",
    "        curr_player+=1\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_player(player, i):\n",
    "    '''\n",
    "    Creates a player for the dataframe\n",
    "    Input beautiful soup object with player, index of current player\n",
    "    Output: dict with player's information\n",
    "    '''\n",
    "    \n",
    "    new_obs = {}\n",
    "\n",
    "    on3_a = player.find('a', class_= \n",
    "                          f\"MuiTypography-root MuiLink-root MuiLink-underlineNone MuiBox-root jss{27 + i * 4} IndustryComparisonFourServicesItem_serviceItemContainer__Vxx5H IndustryComparisonConditionalLink_conditionalLink__C6QoW MuiTypography-colorPrimary\")\n",
    "    ESPN_a = player.find('a', class_= \n",
    "                          f\"MuiTypography-root MuiLink-root MuiLink-underlineNone MuiBox-root jss{29 + i * 4} IndustryComparisonFourServicesItem_serviceItemContainer__Vxx5H IndustryComparisonConditionalLink_conditionalLink__C6QoW MuiTypography-colorPrimary\")\n",
    "    sports247_a = player.find('a', class_= \n",
    "                          f\"MuiTypography-root MuiLink-root MuiLink-underlineNone MuiBox-root jss{28 + i * 4} IndustryComparisonFourServicesItem_serviceItemContainer__Vxx5H IndustryComparisonConditionalLink_conditionalLink__C6QoW MuiTypography-colorPrimary\")\n",
    "    rivals_a = player.find('a', class_= \n",
    "                          f\"MuiTypography-root MuiLink-root MuiLink-underlineNone MuiBox-root jss{30 + i * 4} IndustryComparisonFourServicesItem_serviceItemContainer__Vxx5H IndustryComparisonConditionalLink_conditionalLink__C6QoW MuiTypography-colorPrimary\")\n",
    "\n",
    "    new_obs[\"Player_Name\"] = player.find('a', class_='MuiTypography-root MuiLink-root MuiLink-underlineNone MuiTypography-h5 MuiTypography-colorPrimary').text\n",
    "    new_obs[\"On3_rating\"] = notRivals_rating_assign(on3_a)\n",
    "    new_obs[\"ESPN_rating\"] = notRivals_rating_assign(ESPN_a)\n",
    "    new_obs[\"Rivals_rating\"] = rivals_rating_assign(rivals_a)\n",
    "    new_obs[\"247_rating\"] = notRivals_rating_assign(sports247_a)\n",
    "    new_obs[\"On3SchN\"], new_obs[\"On3SchLoc\"] = get_school_name(player)\n",
    "    \n",
    "    return new_obs\n",
    "        \n",
    "\n",
    "\n",
    "def notRivals_rating_assign(soupObj):\n",
    "    '''\n",
    "    Assign rating from on3 website\n",
    "    Input: beautiful soup object that may contain rating\n",
    "    Output: rating\n",
    "    '''\n",
    "    if soupObj is None or soupObj.find('span', class_ = \"StarRating_overallRating__MTh52 StarRating_gray__xYvHF\") is None:\n",
    "        return 40.9\n",
    "\n",
    "    return soupObj.find('span', class_ = \"StarRating_overallRating__MTh52 StarRating_gray__xYvHF\").text\n",
    "\n",
    "\n",
    "def rivals_rating_assign(soupObj):\n",
    "    '''\n",
    "    Assign rating from on3 website\n",
    "    Input: beautiful soup object that may contain rating\n",
    "    Output: rating\n",
    "    '''\n",
    "    if soupObj is None or soupObj.find('span', class_ = \"StarRating_overallRating__MTh52 StarRating_gray__xYvHF\") is None:\n",
    "        return 2.7\n",
    "\n",
    "    return soupObj.find('span', class_ = \"StarRating_overallRating__MTh52 StarRating_gray__xYvHF\").text\n",
    "\n",
    "\n",
    "def get_school_name(player):\n",
    "    '''\n",
    "    Gets the player's ON3 school name, will be important to get other data later\n",
    "    input: Beautiful soup object for an On3 web page with the player\n",
    "    output: School name + city\n",
    "    '''\n",
    "    school_name = player.find('p', class_='MuiTypography-root IndustryComparisonPlayerItem_hometownContainer__Qvs_0 IndustryComparisonPlayerItem_mobile__ROVeH MuiTypography-body1 MuiTypography-colorTextPrimary')\n",
    "    school_name = school_name.find('span')\n",
    "    school_city = player.find('span', class_='IndustryComparisonPlayerItem_homeTown__8IcYx')\n",
    "    if school_name is not None and school_city is not None:\n",
    "        return (school_name.text, \" (\" + school_city.text + \")\")\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e7a745",
   "metadata": {},
   "source": [
    "# Functions that get MaxPreps positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e45ef253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_google_result(s):\n",
    "    '''\n",
    "    Gets first google result and returns as beautiful soup object\n",
    "    Input: string\n",
    "    Output: beautiful soup object for website\n",
    "    '''\n",
    "    query = '+'.join(s.split())     \n",
    "    url = f\"https://www.google.com/search?q={query}\"\n",
    "    soup = set_up_soup(url)\n",
    "    first_result = soup.find('div', class_='yuRUbf')\n",
    "    \n",
    "    if first_result:\n",
    "        return set_up_soup(first_result.a['href'])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def find_pos_on_maxpreps(name, soup, pos):\n",
    "\n",
    "    try:\n",
    "        jersey_pos = soup.find_all('div', class_ = 'jersey-pos')\n",
    "        sports = soup.find_all('div', class_ = 'sport-name')\n",
    "        li = list(zip(sports, jersey_pos))\n",
    "        sports_x_pos = [pos[1] for i, pos in enumerate(li) if 'Football' in str(li[i][0])][0]\n",
    "        sports_x_pos = sports_x_pos.text.split('â€¢ ')[-1]\n",
    "        sports_x_pos = np.array(sports_x_pos.split(', ')).flatten()\n",
    "        return sports_x_pos\n",
    "    except IndexError:\n",
    "        return np.array([[input_position_from_on3(pos)]])\n",
    "    \n",
    "\n",
    "def input_position_from_on3(pos):\n",
    "    '''\n",
    "    Differentiates between On3 position and Maxpreps positions\n",
    "    Input: On3 position\n",
    "    Output: corresponding maxpreps position (ex. qb should match with qb)\n",
    "    '''\n",
    "    maxpreps_positions = ['QB', 'RB', 'WR', 'TE', 'T', 'G', 'C', 'DE', 'CB', 'FS', 'SS', 'DT', 'MLB', 'OLB']\n",
    "    on3_positions = ['qb', 'rb', 'wr', 'te', 'ot', 'iol', 'xx', 'edge', 'cb', 's', 'xxx', 'dl', 'lb', 'xx', 'ath']\n",
    "\n",
    "    return [maxpreps_positions[on3_positions.index(pos)]]\n",
    "   \n",
    "\n",
    "def assign_pos(jersey_pos, num, poss_positions):\n",
    "    '''\n",
    "    Assigns player to position in dataframe\n",
    "    Inputs: array of positions, number position, offense or defense\n",
    "    Outputs: position to add\n",
    "    '''\n",
    "    counter = 0\n",
    "    for item in jersey_pos:\n",
    "        if item in poss_positions:\n",
    "            counter+=1\n",
    "            if counter == num:\n",
    "                return item\n",
    "    \n",
    "    return \"--\"\n",
    "\n",
    "def get_mp_confName(soup):\n",
    "    '''\n",
    "    Gets a player's athletic conference name, useful for finding all-conference data\n",
    "    Input: Soup object\n",
    "    Output: Conference name of player\n",
    "    '''\n",
    "    team_link = soup.find('a', class_ = 'sc-333a63d7-0 eWSjMq school')['href'] \n",
    "    team_link_rankings = team_link + '/football/22-23/standings/'\n",
    "    soup_team = set_up_soup(team_link_rankings).find(\"h2\", class_ = 'sc-f584fccb-0 hTQrEh heading_125_bold')\n",
    "    \n",
    "    return soup_team.text if soup_team else 'Not Found'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f1cc4",
   "metadata": {},
   "source": [
    "# Functions that get team captain and team ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ae24231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_captain(soup):\n",
    "    '''\n",
    "    Finds whether a player is a team captain or not\n",
    "    Input: maxpreps website beautiful soup object\n",
    "    Output: team captain\n",
    "    '''\n",
    "    try: \n",
    "        teamdata = soup.find('div', class_ = 'teamdata')\n",
    "        sport_arr = soup.find_all('div', class_ = 'sport')\n",
    "        football = [sport_arr[i] for i, sport in enumerate(sport_arr) if 'Football' in str(sport_arr[i])]\n",
    "        if 'Captain' in str(football[0]):\n",
    "            return 1\n",
    "\n",
    "        return 0\n",
    "    except IndexError:\n",
    "        print('Couldn\\'t find team captain for player above')\n",
    "        return 'IndexError'\n",
    "\n",
    "    return 0\n",
    "\n",
    "def get_team_rating(soup):\n",
    "    '''\n",
    "    Gets a player's team rating from maxpreps\n",
    "    Input: soup object of the website\n",
    "    Output: Rating\n",
    "    '''\n",
    "    team_link = soup.find('a', class_ = 'sc-333a63d7-0 eWSjMq school')['href'] \n",
    "    team_link_rankings = team_link + '/football/22-23/rankings/'\n",
    "    soup_team = set_up_soup(team_link_rankings)\n",
    "\n",
    "    trs = soup_team.find_all(\"tr\")\n",
    "    for tr in trs:\n",
    "        if team_link + \"football/22-23/schedule/\" in str(tr):\n",
    "            return tr.find_all(\"td\")[-1].text\n",
    "    \n",
    "    return 'Not_found'\n",
    "\n",
    "def get_mp_potg(soup):\n",
    "    '''\n",
    "    Gets how many times a player has won player of the game, from 2022 and in total\n",
    "    Input: soup object of the website\n",
    "    Output: (How many times player won in 2022, Total number of career times player won potg)\n",
    "    '''\n",
    "    links = soup.find_all('li', class_ = '')\n",
    "    soup_potg = ''\n",
    "    found_soup = 0\n",
    "    for link in links:\n",
    "        if \"awards\" in str(link):\n",
    "            soup_potg = set_up_soup(link.a['href'])\n",
    "            found_soup = 1\n",
    "            break\n",
    "    \n",
    "    if found_soup == 0:\n",
    "        return 0, 0\n",
    "            \n",
    "    buttons = soup_potg.find_all('button')\n",
    "    potg_2022 = 0\n",
    "    potg_before = 0\n",
    "    for button in buttons:\n",
    "        if \"Player of the Game\" in str(button):\n",
    "            if \"2022\" in str(button):\n",
    "                potg_2022+=1\n",
    "            if \"2021\" in str(button) or \"2020\" in str(button) or \"2019\" in str(button):\n",
    "                potg_before+=1\n",
    "    return potg_2022, potg_before + potg_2022\n",
    "\n",
    "def set_up_soup(link):\n",
    "    '''\n",
    "    Sets up a beatuiful soup object for a website\n",
    "    Input: Link for parseable website\n",
    "    Output: Soup object ready for parsing\n",
    "    '''\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=4, backoff_factor=2.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('https://', adapter)\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }  # headers to approve user agent\n",
    "\n",
    "    response = session.get(link, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "def fill_df_position_inplace(df):\n",
    "    '''\n",
    "    Fills a player's position in the dataframe\n",
    "    Input: Df\n",
    "    Output: None\n",
    "    '''\n",
    "    df.at[i, \"MP_OPos1\"] = assign_pos(jersey_pos, 1, off_positions)\n",
    "    df.at[i, \"MP_OPos2\"] = assign_pos(jersey_pos, 2, off_positions)\n",
    "    df.at[i, \"MP_OPos3\"] = assign_pos(jersey_pos, 3, off_positions)\n",
    "    df.at[i, \"MP_DPos1\"] = assign_pos(jersey_pos, 1, def_positions)\n",
    "    df.at[i, \"MP_DPos2\"] = assign_pos(jersey_pos, 2, def_positions)\n",
    "    df.at[i, \"MP_DPos3\"] = assign_pos(jersey_pos, 3, def_positions)\n",
    "    \n",
    "def fill_df_error_inplace(position_dfs, pos, error_type):\n",
    "    if error_type == 'TypeError':\n",
    "        position_dfs[pos].at[i, \"Team_Captain\"] = ''\n",
    "        position_dfs[pos].at[i, \"MPTmRtg\"] = ''\n",
    "        position_dfs[pos].at[i, \"MP_potg_count\"], position_dfs[pos].at[i, \"MP_potg_count_total\"] = ('', '')\n",
    "        position_dfs[pos].at[i, \"conference_name\"] = ''\n",
    "    elif error_type == 'HTTPError':\n",
    "        position_dfs[pos].at[i, \"On3_position\"] = pos\n",
    "        position_dfs[pos].at[i, \"MP_OPos1\"] = 'HTTPErr'\n",
    "        position_dfs[pos].at[i, \"MP_OPos2\"] = ''\n",
    "        position_dfs[pos].at[i, \"MP_OPos3\"] = ''\n",
    "        position_dfs[pos].at[i, \"MP_DPos1\"] = ''\n",
    "        position_dfs[pos].at[i, \"MP_DPos2\"] = ''\n",
    "        position_dfs[pos].at[i, \"MP_DPos3\"] = ''\n",
    "        position_dfs[pos].at[i, \"Team_Captain\"] = ''\n",
    "        position_dfs[pos].at[i, \"MPTmRtg\"] = ''\n",
    "        position_dfs[pos].at[i, \"Team_Captain\"] = ''\n",
    "        position_dfs[pos].at[i, \"MPTmRtg\"] = ''\n",
    "        position_dfs[pos].at[i, \"MP_potg_count\"], position_dfs[pos].at[i, \"MP_potg_count_total\"] = ('', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fbc89",
   "metadata": {},
   "source": [
    "# Code below are the \"main\" functions, what I run to execute data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67fa7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "898f8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "positions = ['qb', 'rb', 'wr', 'te', 'ot', 'iol', 'edge', 'dl', 'lb', 'cb', 's']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43299c7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arch Manning 0\n",
      "[]\n",
      "Couldn't find team captain for player above\n",
      "Dante Moore 1\n",
      "[<div class=\"sport\"><div><a class=\"sc-a2e14072-0 hCsilC\" href=\"https://www.maxpreps.com/mi/detroit/king-crusaders/football/22-23/schedule/\" style=\"--data-color:#004ACE;--data-hover-color:#002cb0\">King Varsity Football</a></div><div>#5 â€¢ QB</div></div>]\n",
      "Nico Iamaleava 2\n",
      "[<div class=\"sport\"><div><a class=\"sc-a2e14072-0 hCsilC\" href=\"https://www.maxpreps.com/ca/downey/warren-bears/football/21-22/schedule/\" style=\"--data-color:#004ACE;--data-hover-color:#002cb0\">Warren Varsity Football</a></div><div>#8 â€¢ QB</div></div>]\n",
      "Jackson Arnold 3\n",
      "[<div class=\"sport\"><div><a class=\"sc-a2e14072-0 hCsilC\" href=\"https://www.maxpreps.com/tx/denton/guyer-wildcats/football/22-23/schedule/\" style=\"--data-color:#004ACE;--data-hover-color:#002cb0\">Guyer Varsity Football</a></div><div>#11 â€¢ QB</div></div>]\n",
      "Malachi Nelson 4\n",
      "[<div class=\"sport\"><div><a class=\"sc-a2e14072-0 hCsilC\" href=\"https://www.maxpreps.com/ca/los-alamitos/los-alamitos-griffins/football/21-22/schedule/\" style=\"--data-color:#004ACE;--data-hover-color:#002cb0\">Los Alamitos Varsity Football</a></div><div>#7 â€¢ QB</div></div>]\n",
      "Jaden Rashada 5\n",
      "[]\n",
      "Couldn't find team captain for player above\n",
      "Eli Holstein 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(name, i) \u001b[38;5;66;03m#shows the player collecting data for\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     soup \u001b[38;5;241m=\u001b[39m get_first_google_result(name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m position_dfs[pos]\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOn3SchN\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m maxpreps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m     school_name \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschool-name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "off_positions = ['QB', 'RB', 'WR', 'TE', 'T', 'C', 'G']\n",
    "def_positions = ['DE', 'CB', 'FS', 'SS', 'DT', 'MLB', 'OLB']\n",
    "maxpreps_positions = np.concatenate((off_positions, def_positions))\n",
    "years = [2023, 2024, 2025, 2026]\n",
    "\n",
    "for year in years:\n",
    "    for pos in positions:\n",
    "        position_dfs = {}\n",
    "        dfs = []\n",
    "        for i in range(1, 6):\n",
    "            url = f\"https://www.on3.com/db/rankings/industry-comparison/football/{year}/?position={pos}&page={i}\"\n",
    "            dfs.append(get_player_ratings_and_school(url))\n",
    "\n",
    "        position_dfs[pos] = pd.concat(dfs)\n",
    "        position_dfs[pos].reset_index(drop=True, inplace=True)\n",
    "        names = list(position_dfs[pos][\"Player_Name\"])\n",
    "        #set up dataframe\n",
    "\n",
    "        for i, name in enumerate(names):\n",
    "            print(name, i) #shows the player collecting data for\n",
    "            try:\n",
    "                time.sleep(2.5 + 0.02 * i)\n",
    "                soup = get_first_google_result(name + \" \" + position_dfs[pos].at[i, 'On3SchN'] + \" maxpreps\")\n",
    "                school_name = soup.find('div', class_ = 'school-name')\n",
    "                school_loc = soup.find('div', class_ = \"location\")\n",
    "                if school_name and school_loc:\n",
    "                    position_dfs[pos].at[i, \"MPSchN\"] = school_name.text + school_loc.text\n",
    "                #assign school name\n",
    "                \n",
    "                jersey_pos = find_pos_on_maxpreps(name, soup, pos) \n",
    "                position_dfs[pos].at[i, \"On3_position\"] = pos\n",
    "                fill_df_position_inplace(position_dfs[pos])\n",
    "                #assign player position\n",
    "                try:\n",
    "                    position_dfs[pos].at[i, \"Team_Captain\"] = get_team_captain(soup)\n",
    "                    position_dfs[pos].at[i, \"MPTmRtg\"] = get_team_rating(soup)\n",
    "                    position_dfs[pos].at[i, \"MP_potg_count\"], position_dfs[pos].at[i, \"MP_potg_count_total\"] = get_mp_potg(soup)\n",
    "                    position_dfs[pos].at[i, \"conference_name\"] = get_mp_confName(soup)\n",
    "                    #assign more player info\n",
    "                except TypeError:\n",
    "                    fill_df_error_inplace(position_dfs, pos, 'TypeError')\n",
    "\n",
    "            except HTTPError:\n",
    "                print('Error encountered')\n",
    "                fill_df_error_inplace(position_dfs, pos, 'HTTPError')\n",
    "\n",
    "            if i % 40 == 0:\n",
    "                time.sleep(10 + 0.05 * i)\n",
    "\n",
    "        position_dfs[pos].to_csv(f\"new_{year}_\" + pos + \"_ratings.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
